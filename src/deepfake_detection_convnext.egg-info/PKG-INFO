Metadata-Version: 2.4
Name: deepfake-detection-convnext
Version: 0.1.0
Summary: Deepfake detection using ConvNeXt on DFDC
Requires-Python: >=3.10
Description-Content-Type: text/markdown

# Deepfake Detection using ConvNeXt (DFDC)

This project trains a ConvNeXt-based classifier to detect deepfake content using the DFDC dataset (frame-level training + video-level voting inference).

## Highlights
- ConvNeXt (timm) backbone
- Frame sampling for video inference
- Majority-vote / mean-probability aggregation
- Reproducible config-driven runs (`configs/default.yaml`)

## Repo Structure
- `notebooks/` Kaggle notebook (training / exploration)
- `src/dfdc/` reusable dataset + model utilities
- `scripts/` CLI entrypoints (train / eval / inference)
- `configs/` YAML configs
- `results/` metrics / plots (small files only)
- `checkpoints/` model weights (ignored by git)

## Setup
```bash
pip install -r requirements.txt
# Deepfake Detection using ConvNeXt

This project explores **deepfake video detection** using a modern ConvNeXt-based image classifier trained on the **DFDC (DeepFake Detection Challenge)** dataset.  
The goal is to evaluate whether strong image backbones can effectively detect manipulated facial frames without explicit temporal modeling.

---

## ğŸ“Œ Motivation
Deepfake videos pose serious threats to:
- Digital media authenticity
- Political misinformation
- Identity fraud

This project investigates:
- Frame-level deepfake detection
- Majority voting across frames
- Model confidence and calibration

---

## ğŸ§  Methodology
- Backbone: **ConvNeXt-Tiny (ImageNet pretrained)**
- Input: Sampled face frames from videos
- Output: Binary classification (REAL vs FAKE)
- Aggregation: Majority voting across frames
- Loss: Cross-entropy
- Metrics: Accuracy, ROC-AUC, confusion matrix

---

## ğŸ“‚ Dataset
- **DFDC (DeepFake Detection Challenge)**
- Real and manipulated face frames
- Dataset accessed via Kaggle

> Dataset is **not included** in this repository.

---

## ğŸ“Š Results (Validation)
| Metric | Value |
|------|------|
| Validation Accuracy | ~84% |
| ROC-AUC | ~0.81 |
| Mean FAKE Prob (REAL frames) | ~0.68 |
| Mean FAKE Prob (FAKE frames) | ~0.86 |

---

## ğŸ”¬ Observations
- ConvNeXt learns strong spatial artifacts
- Frame-level predictions benefit from aggregation
- Some REAL videos show high FAKE confidence â†’ motivates calibration & temporal modeling

---

## ğŸ“ Repository Structure

deepfake-detection-convnext/
â”‚
â”œâ”€â”€ notebooks/        # Kaggle notebooks (training & analysis)
â”œâ”€â”€ src/              # Clean training & inference code
â”œâ”€â”€ results/          # Plots, metrics, confusion matrices
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

---

## ğŸš€ Future Work
- Temporal modeling (CNN + LSTM / Transformers)
- Face alignment & quality filtering
- Cross-dataset generalization
- Model calibration & uncertainty estimation

---

## ğŸ‘¤ Author
**Harshith Siddartha Kutumbaka**  
MS Computer Science (Data Science)  
UNC Charlotte
